{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 2950: Data Cleaning\n",
    "#### Group Members: Anusha Bishayee, Katheryn Ding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### __Data Collection and Cleaning:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, root_mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our original dataset with ESG information for different large/mid-cap companies came in a csv format, which we downloaded from Kaggle. this had about 722 rows, each corresponding to a unique publicly traded company. further description of the columns here can be found in the 'Dataset Description' portion of this notebook.\n",
    "\n",
    "we first dropped all rows that had null values, which eliminated 27 companies. we then filtered this dataset for just USD currency, excluding companies that are traded in CNY or any other currency. this allows us to have greater familiarity with the industries and companies we analyze - this process eliminated 15 more of our rows, and left us with 680 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (722, 21)\n",
      "non-null data shape: (695, 21)\n",
      "refined data shape: (680, 21)\n"
     ]
    }
   ],
   "source": [
    "esg = pd.read_csv(\"esg_data.csv\")\n",
    "print(f\"original data shape: {esg.shape}\")\n",
    "\n",
    "esg = esg.dropna()\n",
    "print(f\"non-null data shape: {esg.shape}\")\n",
    "\n",
    "esg = esg[esg[\"currency\"] == \"USD\"]\n",
    "print(f\"refined data shape: {esg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, we converted the 'last_processing_date' column in our dataset to DateTime format - a lot of rows had a differing date formats as well, so we had to convert them all to m/d/y. after that, we sorted the dataset by ascending and descending 'last_processing_date' to see the range of processing dates in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest dates:\n",
      "720    11-15-2022\n",
      "716    11-15-2022\n",
      "Name: last_processing_date, dtype: object\n",
      "\n",
      "earliest dates:\n",
      "658    02-08-2022\n",
      "36     04-16-2022\n",
      "Name: last_processing_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "esg[\"last_processing_date\"] = pd.to_datetime(esg[\"last_processing_date\"], format = \"mixed\")\n",
    "esg[\"last_processing_date\"] = esg[\"last_processing_date\"].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "esg = esg.sort_values(by = \"last_processing_date\", ascending = False)\n",
    "print(f\"latest dates:\\n{esg[\"last_processing_date\"].head(2)}\")\n",
    "\n",
    "esg = esg.sort_values(by = \"last_processing_date\", ascending = True)\n",
    "print(f\"\\nearliest dates:\\n{esg[\"last_processing_date\"].head(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after this, we realized we have two 'Energy' values for the 'industry' column - one is 'Energy ' and one is 'Energy'. we renamed all the 'Energy ' values, and also re-formatted some other industry column values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Leisure Products' 'Semiconductors' 'Health Care' 'Chemicals'\n",
      " 'Telecommunication' 'Consumer Products' 'Airlines' 'Insurance'\n",
      " 'Communications' 'Building' 'Technology' 'Logistics & Transportation'\n",
      " 'Biotechnology' 'Banking' 'Pharmaceuticals' 'Financial Services'\n",
      " 'Life Sciences Tools & Services' 'Electrical Equipment' 'Real Estate'\n",
      " 'Machinery' 'Retail' 'Food Products' 'Industrial Conglomerates'\n",
      " 'Hotels, Restaurants, & Leisure' 'Utilities' 'Beverages' 'Tobacco'\n",
      " 'Media' 'Auto Components' 'Energy' 'Commercial Services & Supplies'\n",
      " 'Packaging' 'Road & Rail' 'Metals & Mining'\n",
      " 'Textiles, Apparel, & Luxury Goods' 'Trading Companies & Distributors'\n",
      " 'Aerospace & Defense' 'Automobiles' 'Distributors'\n",
      " 'Professional Services' 'Construction' 'Marine'\n",
      " 'Diversified Consumer Services']\n"
     ]
    }
   ],
   "source": [
    "esg['industry'] = esg['industry'].replace('Energy ', 'Energy')\n",
    "esg['industry'] = esg['industry'].replace('Hotels, Restaurants & Leisure', 'Hotels, Restaurants, & Leisure')\n",
    "esg['industry'] = esg['industry'].replace('Hotels Restaurants and Leisure', 'Hotels, Restaurants, & Leisure')\n",
    "esg['industry'] = esg['industry'].replace('Consumer products', 'Consumer Products')\n",
    "esg['industry'] = esg['industry'].replace('Logistics and Transportation', 'Logistics & Transportation')\n",
    "esg['industry'] = esg['industry'].replace('Life Sciences Tools and Services', 'Life Sciences Tools & Services')\n",
    "esg['industry'] = esg['industry'].replace('Commercial Services and Supplies', 'Commercial Services & Supplies')\n",
    "esg['industry'] = esg['industry'].replace('Road and Rail', 'Road & Rail')\n",
    "esg['industry'] = esg['industry'].replace('Metals and Mining', 'Metals & Mining')\n",
    "esg['industry'] = esg['industry'].replace('Aerospace and Defense', 'Aerospace & Defense')\n",
    "esg['industry'] = esg['industry'].replace('Textiles Apparel and Luxury Goods', 'Textiles, Apparel, & Luxury Goods')\n",
    "esg['industry'] = esg['industry'].replace('Trading Companies and Distributors', 'Trading Companies & Distributors')\n",
    "\n",
    "print(esg['industry'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we wanted to add our finance data from the yfinance library onto to our esg dataset. we used the ticker column to match up companies from the yfinance library and our esg dataset, and we set our dates of the finance data to range from 2/1/21 to 12/31/22, as all of the 'last processing date' values for the esg data range from 2/8/22 to 11/15/22. in specific, we calculated a stock percentage change over this period for each company, a volatility index, a 50-day moving average, and a cumulative return metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents some annoying yfinance outputs from printing, gpt was used to assist here\n",
    "@contextlib.contextmanager\n",
    "def suppress_output():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "tickers = esg[\"ticker\"].tolist()\n",
    "stock_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # suppresses all of the outputs when grabbing data from yfinance\n",
    "        with suppress_output():  \n",
    "            stock = yf.download(ticker, start = \"2021-02-01\", end = \"2022-12-31\", progress = False)\n",
    "        \n",
    "        if not stock.empty:\n",
    "            # get closing price for 01/01/2021 and 12/31/2022\n",
    "            close_2021_02_01 = stock.loc[\"2021-02-01\"][\"Close\"] if \"2021-02-01\" in stock.index else None\n",
    "            close_2022_12_31 = stock.loc[\"2022-12-30\"][\"Close\"] if \"2022-12-30\" in stock.index else None\n",
    "\n",
    "            # calculating percentage change\n",
    "            percentage_change = ((stock[\"Close\"].iloc[-1] - stock[\"Close\"].iloc[0]) / stock[\"Close\"].iloc[0]) * 100\n",
    "            \n",
    "            # calculating volatility (sd of daily returns)\n",
    "            daily_returns = stock[\"Close\"].pct_change()\n",
    "            volatility = daily_returns.std()\n",
    "            \n",
    "            # calculating 50-day moving average\n",
    "            stock[\"50_day_SMA\"] = stock[\"Close\"].rolling(window=50).mean()\n",
    "            sma_50_day = stock[\"50_day_SMA\"].iloc[-1]\n",
    "            \n",
    "            # calculating cumulative return\n",
    "            cumulative_return = (stock[\"Close\"].iloc[-1] / stock[\"Close\"].iloc[0]) - 1\n",
    "            \n",
    "            stock_data.append({\n",
    "                'ticker': ticker, \n",
    "                'start_close': close_2021_02_01,\n",
    "                'end_close': close_2022_12_31,\n",
    "                'percentage_change': percentage_change,\n",
    "                'volatility': volatility,\n",
    "                '50_day_SMA': sma_50_day,\n",
    "                'cumulative_return': cumulative_return\n",
    "            })\n",
    "            \n",
    "    # also helps to suppress annoying outputs\n",
    "    except (yf.YFTzMissingError, yf.YFPricesMissingError):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we needed to convert the stock data we extracted from yfinance to a dataframe, so that we can merge it with our original esg dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current data shape: (680, 27)\n",
      "\n",
      "  ticker                           name currency  \\\n",
      "0   poww                       Ammo Inc      USD   \n",
      "1   acls       Axcelis Technologies Inc      USD   \n",
      "2   achc  Acadia Healthcare Company Inc      USD   \n",
      "3     cf     CF Industries Holdings Inc      USD   \n",
      "4      t                       AT&T Inc      USD   \n",
      "\n",
      "                        exchange           industry  \\\n",
      "0     NASDAQ NMS - GLOBAL MARKET   Leisure Products   \n",
      "1     NASDAQ NMS - GLOBAL MARKET     Semiconductors   \n",
      "2     NASDAQ NMS - GLOBAL MARKET        Health Care   \n",
      "3  NEW YORK STOCK EXCHANGE, INC.          Chemicals   \n",
      "4  NEW YORK STOCK EXCHANGE, INC.  Telecommunication   \n",
      "\n",
      "                                                logo  \\\n",
      "0  https://static.finnhub.io/logo/8decc6ca0564a89...   \n",
      "1  https://static.finnhub.io/logo/88b5f730-80df-1...   \n",
      "2  https://static.finnhub.io/logo/4b6b2e5a4cfce5b...   \n",
      "3  https://static.finnhub.io/logo/9b57a636-80eb-1...   \n",
      "4  https://static.finnhub.io/logo/7d20269e-80ec-1...   \n",
      "\n",
      "                              weburl environment_grade environment_level  \\\n",
      "0               https://ammoinc.com/                 B            Medium   \n",
      "1           https://www.axcelis.com/                 A              High   \n",
      "2  https://www.acadiahealthcare.com/                BB            Medium   \n",
      "3      https://www.cfindustries.com/                 A              High   \n",
      "4               https://www.att.com/                 B            Medium   \n",
      "\n",
      "  social_grade  ... last_processing_date total_grade total_level      cik  \\\n",
      "0            B  ...           02-08-2022           B      Medium  1015383   \n",
      "1           BB  ...           04-16-2022         BBB        High  1113232   \n",
      "2            B  ...           04-16-2022          BB      Medium  1520697   \n",
      "3           BB  ...           04-16-2022         BBB        High  1324404   \n",
      "4            B  ...           04-16-2022           B      Medium   732717   \n",
      "\n",
      "   start_close  end_close  percentage_change volatility 50_day_SMA  \\\n",
      "0     5.400000   1.730000         -67.962963   0.040577     2.3782   \n",
      "1    36.150002  79.360001         119.529730   0.038259    73.6454   \n",
      "2    52.990002  82.320000          55.350061   0.021303    82.6706   \n",
      "3    42.970001  85.199997          98.277856   0.027433   101.2440   \n",
      "4    21.638973  18.410000         -14.922027   0.015132    18.5720   \n",
      "\n",
      "  cumulative_return  \n",
      "0         -0.679630  \n",
      "1          1.195297  \n",
      "2          0.553501  \n",
      "3          0.982779  \n",
      "4         -0.149220  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "stock_df = pd.DataFrame(stock_data)\n",
    "merged_df = esg.merge(stock_df, on = 'ticker', how = 'left')\n",
    "print(f\"current data shape: {merged_df.shape}\")\n",
    "print(f\"\\n{merged_df.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after that, we needed to drop any rows where the finance data join has left null values. this eliminates 80 more of our rows, leaving us with 600 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-null finance data shape: (597, 27)\n",
      "\n",
      "<bound method NDFrame.head of     ticker                             name currency  \\\n",
      "71     mmm                            3M Co      USD   \n",
      "142    aos                   A O Smith Corp      USD   \n",
      "661   abvc               ABVC Biopharma Inc      USD   \n",
      "17    acad       ACADIA Pharmaceuticals Inc      USD   \n",
      "41    aciw                ACI Worldwide Inc      USD   \n",
      "..     ...                              ...      ...   \n",
      "500    zts                       Zoetis Inc      USD   \n",
      "571    zuo                        Zuora Inc      USD   \n",
      "643    zws  Zurn Elkay Water Solutions Corp      USD   \n",
      "647   zyme                    Zymeworks Inc      USD   \n",
      "189   ebay                         eBay Inc      USD   \n",
      "\n",
      "                          exchange                  industry  \\\n",
      "71   NEW YORK STOCK EXCHANGE, INC.  Industrial Conglomerates   \n",
      "142  NEW YORK STOCK EXCHANGE, INC.                  Building   \n",
      "661     NASDAQ NMS - GLOBAL MARKET             Biotechnology   \n",
      "17      NASDAQ NMS - GLOBAL MARKET             Biotechnology   \n",
      "41      NASDAQ NMS - GLOBAL MARKET                Technology   \n",
      "..                             ...                       ...   \n",
      "500  NEW YORK STOCK EXCHANGE, INC.           Pharmaceuticals   \n",
      "571  NEW YORK STOCK EXCHANGE, INC.                Technology   \n",
      "643  NEW YORK STOCK EXCHANGE, INC.                  Building   \n",
      "647  NEW YORK STOCK EXCHANGE, INC.             Biotechnology   \n",
      "189     NASDAQ NMS - GLOBAL MARKET                    Retail   \n",
      "\n",
      "                                                  logo  \\\n",
      "71   https://static.finnhub.io/logo/2a1802fa-80ec-1...   \n",
      "142  https://static.finnhub.io/logo/73381be8-80eb-1...   \n",
      "661  https://static.finnhub.io/logo/2b1c9fbcfafa70d...   \n",
      "17   https://static.finnhub.io/logo/2d87da57d47f7a5...   \n",
      "41   https://static.finnhub.io/logo/875c5a76-80df-1...   \n",
      "..                                                 ...   \n",
      "500  https://static.finnhub.io/logo/aae505a6-80cd-1...   \n",
      "571  https://static.finnhub.io/logo/181c3c26-80db-1...   \n",
      "643  https://static.finnhub.io/logo/166822dc-80c9-1...   \n",
      "647  https://static.finnhub.io/logo/d5054e357d522c9...   \n",
      "189  https://static.finnhub.io/logo/919a6270-826a-1...   \n",
      "\n",
      "                              weburl environment_grade environment_level  \\\n",
      "71               https://www.3m.com/                 A              High   \n",
      "142         https://www.aosmith.com/                 A              High   \n",
      "661          https://abvcpharma.com/                 B            Medium   \n",
      "17               https://acadia.com/                 B            Medium   \n",
      "41     https://www.aciworldwide.com/                 A              High   \n",
      "..                               ...               ...               ...   \n",
      "500          https://www.zoetis.com/                 A              High   \n",
      "571           https://www.zuora.com/                 B            Medium   \n",
      "643  https://zurnwatersolutions.com/                 A              High   \n",
      "647       https://www.zymeworks.com/                 B            Medium   \n",
      "189         https://www.ebayinc.com/                 A              High   \n",
      "\n",
      "    social_grade  ... last_processing_date total_grade total_level      cik  \\\n",
      "71            BB  ...           04-16-2022         BBB        High    66740   \n",
      "142           BB  ...           04-16-2022         BBB        High    91142   \n",
      "661            B  ...           11-06-2022           B      Medium  1173313   \n",
      "17             B  ...           04-16-2022          BB      Medium  1070494   \n",
      "41            BB  ...           04-16-2022         BBB        High   935036   \n",
      "..           ...  ...                  ...         ...         ...      ...   \n",
      "500           BB  ...           04-20-2022         BBB        High  1555280   \n",
      "571            B  ...           09-24-2022           B      Medium  1423774   \n",
      "643           BB  ...           11-06-2022         BBB        High  1439288   \n",
      "647           BB  ...           11-06-2022          BB      Medium  1403752   \n",
      "189           BB  ...           04-17-2022         BBB        High  1065088   \n",
      "\n",
      "     start_close   end_close  percentage_change volatility  50_day_SMA  \\\n",
      "71    146.070236  100.267555         -31.356615   0.014472  104.066388   \n",
      "142    56.029999   57.240002           2.159563   0.018196   57.343600   \n",
      "661    50.000000    6.250000         -87.500000   0.089921    7.173200   \n",
      "17     46.580002   15.920000         -65.822242   0.045374   15.391400   \n",
      "41     39.590000   23.000000         -41.904522   0.021739   21.438400   \n",
      "..           ...         ...                ...        ...         ...   \n",
      "500   155.580002  146.550003          -5.804087   0.016947  147.633001   \n",
      "571    14.240000    6.360000         -55.337077   0.034177    7.057200   \n",
      "643    38.889999   21.150000         -45.615840   0.032776   23.315800   \n",
      "647    35.639999    7.860000         -77.946127   0.049518    7.356000   \n",
      "189    58.470001   41.470001         -29.074739   0.022532   42.343200   \n",
      "\n",
      "    cumulative_return  \n",
      "71          -0.313566  \n",
      "142          0.021596  \n",
      "661         -0.875000  \n",
      "17          -0.658222  \n",
      "41          -0.419045  \n",
      "..                ...  \n",
      "500         -0.058041  \n",
      "571         -0.553371  \n",
      "643         -0.456158  \n",
      "647         -0.779461  \n",
      "189         -0.290747  \n",
      "\n",
      "[597 rows x 27 columns]>\n"
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.dropna()\n",
    "print(f\"non-null finance data shape: {merged_df.shape}\\n\")\n",
    "\n",
    "merged_df = merged_df.sort_values(by = \"name\", ascending = True)\n",
    "print(merged_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ticker', 'name', 'currency', 'industry', 'environment_grade',\n",
       "       'environment_level', 'social_grade', 'social_level', 'governance_grade',\n",
       "       'governance_level', 'environment_score', 'social_score',\n",
       "       'governance_score', 'total_score', 'last_processing_date',\n",
       "       'total_grade', 'total_level', 'start_close', 'end_close',\n",
       "       'percentage_change', 'volatility', '50_day_SMA', 'cumulative_return'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merged_df.drop(['exchange', 'logo', 'weburl','cik'],axis=1)\n",
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is still a lot of data, but will be helpful for getting industry-level and other general overviews of the data. merged_df will be our main dataframe.\n",
    "   \n",
    "we also want to create a sample of these 600 companies so that we are able to look at trends and associations at the individual company-level as well.   \n",
    "   \n",
    "since we want to take random sample stratum on industries and total ESG score:\n",
    "1. We first list all industries with descending total_score, then separate the industries based on total_score into three groups: high/medium/low ESG based on their rank.\n",
    "2. Then, we use  .sample() to randomly choose two industries from each group, which generates 6 industries.\n",
    "3. For each of the randomly chosen industries, we randomly pick 5 companies from each industry, which generates 30 companies in the sample_companies.\n",
    "   \n",
    "By applying this sampling process, we ensure our sample by industries is representative of all levels of ESG scores. gpt was used here for assistance with the sampling. sample_companies will be our 2nd dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "randomly selected high ESG industries: ['Building', 'Road & Rail']\n",
      "randomly selected medium ESG industries: ['Professional Services', 'Real Estate']\n",
      "randomly selected low ESG industries: ['Biotechnology', 'Banking']\n",
      "  ticker                              name currency               industry  \\\n",
      "0     tt            Trane Technologies PLC      USD               Building   \n",
      "1    mas                        Masco Corp      USD               Building   \n",
      "2    zws   Zurn Elkay Water Solutions Corp      USD               Building   \n",
      "3    aos                    A O Smith Corp      USD               Building   \n",
      "4   aaon                          Aaon Inc      USD               Building   \n",
      "5    xpo                 XPO Logistics Inc      USD            Road & Rail   \n",
      "6    unp                Union Pacific Corp      USD            Road & Rail   \n",
      "7    csx                          CSX Corp      USD            Road & Rail   \n",
      "8    nsc             Norfolk Southern Corp      USD            Road & Rail   \n",
      "9   odfl     Old Dominion Freight Line Inc      USD            Road & Rail   \n",
      "0   ldos               Leidos Holdings Inc      USD  Professional Services   \n",
      "1    efx                       Equifax Inc      USD  Professional Services   \n",
      "2   upwk                        Upwork Inc      USD  Professional Services   \n",
      "3   vrsk              Verisk Analytics Inc      USD  Professional Services   \n",
      "4    rhi     Robert Half International Inc      USD  Professional Services   \n",
      "5   well                  Welltower OP LLC      USD            Real Estate   \n",
      "6    amt               American Tower Corp      USD            Real Estate   \n",
      "7    vtr                        Ventas Inc      USD            Real Estate   \n",
      "8    dlr          Digital Realty Trust Inc      USD            Real Estate   \n",
      "9   eqix                       Equinix Inc      USD            Real Estate   \n",
      "0    cfg      Citizens Financial Group Inc      USD                Banking   \n",
      "1    mtb                     M&T Bank Corp      USD                Banking   \n",
      "2    tfc             Truist Financial Corp      USD                Banking   \n",
      "3    pnc  PNC Financial Services Group Inc      USD                Banking   \n",
      "4    hbt                 HBT Financial Inc      USD                Banking   \n",
      "5   zyme                     Zymeworks Inc      USD          Biotechnology   \n",
      "6   adma                ADMA Biologics Inc      USD          Biotechnology   \n",
      "7   urgn                 Urogen Pharma Ltd      USD          Biotechnology   \n",
      "8   adtx                        Aditxt Inc      USD          Biotechnology   \n",
      "9   biib                        Biogen Inc      USD          Biotechnology   \n",
      "\n",
      "  environment_grade environment_level social_grade social_level  \\\n",
      "0                AA         Excellent           BB       Medium   \n",
      "1                 A              High           BB       Medium   \n",
      "2                 A              High           BB       Medium   \n",
      "3                 A              High           BB       Medium   \n",
      "4                 A              High           BB       Medium   \n",
      "5                 A              High           BB       Medium   \n",
      "6                 B            Medium            B       Medium   \n",
      "7                 A              High           BB       Medium   \n",
      "8                BB            Medium           BB       Medium   \n",
      "9               BBB              High          BBB         High   \n",
      "0                 A              High           BB       Medium   \n",
      "1                BB            Medium           BB       Medium   \n",
      "2                 B            Medium            B       Medium   \n",
      "3                AA         Excellent           BB       Medium   \n",
      "4                 B            Medium           BB       Medium   \n",
      "5               BBB              High           BB       Medium   \n",
      "6                 A              High           BB       Medium   \n",
      "7                 A              High           BB       Medium   \n",
      "8                 A              High           BB       Medium   \n",
      "9                 A              High           BB       Medium   \n",
      "0                 B            Medium            B       Medium   \n",
      "1                 A              High           BB       Medium   \n",
      "2               BBB              High           BB       Medium   \n",
      "3               BBB              High           BB       Medium   \n",
      "4                 B            Medium            B       Medium   \n",
      "5                 B            Medium           BB       Medium   \n",
      "6                 B            Medium            B       Medium   \n",
      "7                 B            Medium            B       Medium   \n",
      "8                 B            Medium            B       Medium   \n",
      "9                BB            Medium           BB       Medium   \n",
      "\n",
      "  governance_grade governance_level  ...  last_processing_date  total_grade  \\\n",
      "0               BB           Medium  ...            11-06-2022            A   \n",
      "1               BB           Medium  ...            04-18-2022          BBB   \n",
      "2               BB           Medium  ...            11-06-2022          BBB   \n",
      "3               BB           Medium  ...            04-16-2022          BBB   \n",
      "4                B           Medium  ...            04-16-2022          BBB   \n",
      "5               BB           Medium  ...            04-20-2022          BBB   \n",
      "6                B           Medium  ...            04-19-2022           BB   \n",
      "7               BB           Medium  ...            04-17-2022          BBB   \n",
      "8               BB           Medium  ...            04-18-2022          BBB   \n",
      "9                B           Medium  ...            04-18-2022          BBB   \n",
      "0               BB           Medium  ...            04-18-2022          BBB   \n",
      "1               BB           Medium  ...            10-06-2022          BBB   \n",
      "2                B           Medium  ...            10-06-2022           BB   \n",
      "3               BB           Medium  ...            04-19-2022            A   \n",
      "4               BB           Medium  ...            04-19-2022           BB   \n",
      "5               BB           Medium  ...            04-21-2022          BBB   \n",
      "6               BB           Medium  ...            04-16-2022          BBB   \n",
      "7               BB           Medium  ...            04-19-2022          BBB   \n",
      "8               BB           Medium  ...            04-17-2022          BBB   \n",
      "9               BB           Medium  ...            04-17-2022          BBB   \n",
      "0                B           Medium  ...            04-16-2022            B   \n",
      "1                B           Medium  ...            04-18-2022          BBB   \n",
      "2               BB           Medium  ...            11-06-2022          BBB   \n",
      "3               BB           Medium  ...            04-18-2022          BBB   \n",
      "4               BB           Medium  ...            10-06-2022           BB   \n",
      "5               BB           Medium  ...            11-06-2022           BB   \n",
      "6               BB           Medium  ...            04-16-2022           BB   \n",
      "7                B           Medium  ...            10-06-2022           BB   \n",
      "8               BB           Medium  ...            10-06-2022            B   \n",
      "9               BB           Medium  ...            04-16-2022          BBB   \n",
      "\n",
      "   total_level    start_close    end_close percentage_change volatility  \\\n",
      "0         High     142.750000   168.089996         17.751311   0.017016   \n",
      "1         High      55.080002    46.669998        -15.268706   0.018719   \n",
      "2         High      38.889999    21.150000        -45.615840   0.032776   \n",
      "3         High      56.029999    57.240002          2.159563   0.018196   \n",
      "4         High      49.973331    50.213333          0.480260   0.020646   \n",
      "5         High      39.738617    33.290001        -16.227580   0.028413   \n",
      "6       Medium     198.600006   207.070007          4.264854   0.014568   \n",
      "7         High      29.016666    30.980000          6.766226   0.015786   \n",
      "8         High     239.910004   246.419998          2.713515   0.016159   \n",
      "9         High      99.550003   141.889999         42.531386   0.021535   \n",
      "0         High     105.059998   105.190002          0.123743   0.015973   \n",
      "1         High     180.309998   194.360001          7.792138   0.021956   \n",
      "2       Medium      45.110001    10.440000        -76.856574   0.044098   \n",
      "3         High     185.940002   176.419998         -5.119933   0.016003   \n",
      "4       Medium      68.699997    73.830002          7.467256   0.019270   \n",
      "5         High      62.509998    65.550003          4.863230   0.016966   \n",
      "6         High     235.570007   211.860001        -10.064951   0.016860   \n",
      "7         High      47.560001    45.049999         -5.277548   0.017761   \n",
      "8         High     148.210007   100.269997        -32.346001   0.018200   \n",
      "9         High     756.719971   655.030029        -13.438253   0.019535   \n",
      "0       Medium      37.209999    39.369999          5.804891   0.021152   \n",
      "1         High     132.949997   145.059998          9.108688   0.020756   \n",
      "2         High      48.380001    43.029999        -11.058293   0.019116   \n",
      "3         High     145.860001   157.940002          8.281915   0.017795   \n",
      "4       Medium      15.060000    19.570000         29.946874   0.017339   \n",
      "5       Medium      35.639999     7.860000        -77.946127   0.049518   \n",
      "6       Medium       2.450000     3.880000         58.367349   0.041680   \n",
      "7       Medium      21.870001     8.870000        -59.442160   0.043236   \n",
      "8       Medium  260800.000000  1848.000000        -99.291411   0.102587   \n",
      "9         High     278.459991   276.920013         -0.553034   0.031692   \n",
      "\n",
      "    50_day_SMA  cumulative_return  ESG score level  \n",
      "0   169.433000           0.177513             High  \n",
      "1    48.071000          -0.152687             High  \n",
      "2    23.315800          -0.456158             High  \n",
      "3    57.343600           0.021596             High  \n",
      "4    49.237200           0.004803             High  \n",
      "5    34.973681          -0.162276             High  \n",
      "6   207.042801           0.042649             High  \n",
      "7    30.759800           0.067662             High  \n",
      "8   241.700600           0.027135             High  \n",
      "9   144.182400           0.425314             High  \n",
      "0   105.201200           0.001237           Medium  \n",
      "1   186.466199           0.077921           Medium  \n",
      "2    12.001400          -0.768566           Medium  \n",
      "3   176.626599          -0.051199           Medium  \n",
      "4    75.301000           0.074673           Medium  \n",
      "5    65.386000           0.048632           Medium  \n",
      "6   210.900200          -0.100650           Medium  \n",
      "7    43.266000          -0.052775           Medium  \n",
      "8   104.035600          -0.323460           Medium  \n",
      "9   637.711002          -0.134383           Medium  \n",
      "0    39.932600           0.058049              Low  \n",
      "1   159.723800           0.091087              Low  \n",
      "2    43.858000          -0.110583              Low  \n",
      "3   158.468999           0.082819              Low  \n",
      "4    20.027400           0.299469              Low  \n",
      "5     7.356000          -0.779461              Low  \n",
      "6     3.206800           0.583673              Low  \n",
      "7     9.235600          -0.594422              Low  \n",
      "8  2963.200000          -0.992914              Low  \n",
      "9   287.571201          -0.005530              Low  \n",
      "\n",
      "[30 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n",
    "np.random.seed(123)\n",
    "\n",
    "avg_esg_by_industry = merged_df.groupby('industry')['total_score'].mean().reset_index()\n",
    "avg_esg_by_industry.columns = ['Industry', 'Average Total ESG Score']\n",
    "avg_esg_by_industry = avg_esg_by_industry.sort_values(by = 'Average Total ESG Score', ascending = False)\n",
    "\n",
    "third = len(avg_esg_by_industry) // 3\n",
    "high_group = avg_esg_by_industry.iloc[:third]\n",
    "medium_group = avg_esg_by_industry.iloc[third: 2 * third]\n",
    "low_group = avg_esg_by_industry.iloc[2 * third:]\n",
    "\n",
    "random_high_industries = high_group.sample(2)['Industry'].tolist()\n",
    "random_medium_industries = medium_group.sample(2)['Industry'].tolist()\n",
    "random_low_industries = low_group.sample(2)['Industry'].tolist()\n",
    "\n",
    "print(f\"randomly selected high ESG industries: {random_high_industries}\")\n",
    "print(f\"randomly selected medium ESG industries: {random_medium_industries}\")\n",
    "print(f\"randomly selected low ESG industries: {random_low_industries}\")\n",
    "\n",
    "high_industry_companies = merged_df[merged_df['industry'].isin(random_high_industries)]\n",
    "medium_industry_companies = merged_df[merged_df['industry'].isin(random_medium_industries)]\n",
    "low_industry_companies = merged_df[merged_df['industry'].isin(random_low_industries)]\n",
    "\n",
    "high_industry_companies_sampled = high_industry_companies.groupby('industry', group_keys = False).apply(lambda x: x.sample(min(len(x), 5))).reset_index(drop = True)\n",
    "high_industry_companies_sampled['ESG score level'] = 'High'\n",
    "medium_industry_companies_sampled = medium_industry_companies.groupby('industry', group_keys = False).apply(lambda x: x.sample(min(len(x), 5))).reset_index(drop = True)\n",
    "medium_industry_companies_sampled['ESG score level'] = 'Medium'\n",
    "low_industry_companies_sampled = low_industry_companies.groupby('industry', group_keys = False).apply(lambda x: x.sample(min(len(x), 5))).reset_index(drop = True)\n",
    "low_industry_companies_sampled['ESG score level'] = 'Low'\n",
    "\n",
    "sample_companies = pd.concat([high_industry_companies_sampled, medium_industry_companies_sampled, low_industry_companies_sampled])\n",
    "print(sample_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, we also extracted some general S&P 500 data from yfinance, ranging from the dates of 2/1/21 and 12/31/22 for the same reason. we are pulling this data so that we can compare stock performance of the individual companies to the overall S&P 500 in the same time range. sp500 will be our 3rd dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Start Price    End Price  Rate of Change\n",
      "Date                                                \n",
      "2021-02-01  3731.169922  3773.860107        1.144150\n",
      "2021-02-02  3791.840088  3826.310059        0.909057\n",
      "2021-02-03  3840.270020  3830.169922       -0.263005\n",
      "2021-02-04  3836.659912  3871.739990        0.914339\n",
      "2021-02-05  3878.300049  3886.830078        0.219942\n",
      "...                 ...          ...             ...\n",
      "2022-12-23  3815.110107  3844.820068        0.778745\n",
      "2022-12-27  3843.340088  3829.250000       -0.366610\n",
      "2022-12-28  3829.560059  3783.219971       -1.210063\n",
      "2022-12-29  3805.449951  3849.280029        1.151771\n",
      "2022-12-30  3829.060059  3839.500000        0.272650\n",
      "\n",
      "[484 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sp500data = yf.download('^GSPC', start = '2021-02-01', end = '2022-12-31', progress = False)\n",
    "sp500 = pd.DataFrame({\n",
    "    'Date': sp500data.index,\n",
    "    'Start Price': sp500data['Open'],\n",
    "    'End Price': sp500data['Close'],\n",
    "    'Rate of Change': ((sp500data['Close'] - sp500data['Open']) / sp500data['Open']) * 100 })\n",
    "\n",
    "sp500.set_index('Date', inplace = True)\n",
    "print(sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we will convert some of our dataframes into csv to use in the next stages of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500.to_csv('sp500.csv', index = False) \n",
    "sample_companies.to_csv('sample_companies.csv', index = False) \n",
    "avg_esg_by_industry.to_csv('avg_esg_by_industry.csv', index = False) \n",
    "merged_df.to_csv('merged_df.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
