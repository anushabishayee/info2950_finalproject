{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO 2950: Phase 2 \n",
    "#### Group Members: Anusha Bishayee, Katheryn Ding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __Research Question:__  \n",
    "\n",
    "#### How do ESG score and stock performance (price) align across different industries? What associations can we find between company industry, stock performance, and ESG ratings?\n",
    "#### note: ESG score refers to a quantiative metric measuring a company's environmental, social, and governance performance; 'environmental' pertains to aspects like waste management and energy emissions, 'social' pertains to aspects like customer satisfaction and DEI in the workplace, and 'governance' pertains to aspects like operating efficiencies and risk management. esg scores are typically examined by investors, analysts, and competitiors to assess risk or opportunities associated with a specific company's practices.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __Data Collection and Cleaning:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sys\n",
    "import warnings\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our original dataset with ESG information for different large/mid-cap companies came in a csv format, which we downloaded from Kaggle. this had about 722 rows, each corresponding to a unique publicly traded company. further description of the columns here can be found in the 'Dataset Description' portion of this notebook.\n",
    "\n",
    "we first dropped all rows that had null values, which eliminated 27 companies. we then filtered this dataset for just USD currency, excluding companies that are traded in CNY or any other currency. this allows us to have greater familiarity with the industries and companies we analyze - this process eliminated 15 more of our rows, and left us with 680 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data shape: (722, 21)\n",
      "non-null data shape: (695, 21)\n",
      "refined data shape: (680, 21)\n"
     ]
    }
   ],
   "source": [
    "esg = pd.read_csv(\"esg_data.csv\")\n",
    "print(f\"original data shape: {esg.shape}\")\n",
    "\n",
    "esg = esg.dropna()\n",
    "print(f\"non-null data shape: {esg.shape}\")\n",
    "\n",
    "esg = esg[esg[\"currency\"] == \"USD\"]\n",
    "print(f\"refined data shape: {esg.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, we converted the 'last_processing_date' column in our dataset to DateTime format (and m/d/y), and sorted the datase by ascending and descending 'last_processing_date' to see the range of processing dates in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest dates:\n",
      "720    11-15-2022\n",
      "716    11-15-2022\n",
      "Name: last_processing_date, dtype: object\n",
      "\n",
      "earliest dates:\n",
      "658    02-08-2022\n",
      "36     04-16-2022\n",
      "Name: last_processing_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "esg[\"last_processing_date\"] = pd.to_datetime(esg[\"last_processing_date\"], format = \"mixed\")\n",
    "esg[\"last_processing_date\"] = esg[\"last_processing_date\"].dt.strftime('%m-%d-%Y')\n",
    "\n",
    "esg = esg.sort_values(by = \"last_processing_date\", ascending = False)\n",
    "print(f\"latest dates:\\n{esg[\"last_processing_date\"].head(2)}\")\n",
    "\n",
    "esg = esg.sort_values(by = \"last_processing_date\", ascending = True)\n",
    "print(f\"\\nearliest dates:\\n{esg[\"last_processing_date\"].head(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we want to add our finance data from the yfinance library onto to our esg dataset. we used the ticker column to match up companies from the yfinance library and our esg dataset, and we set our dates of the finance data to range from 1/1/21 to 12/31/22, as all of the 'last processing date' values for the esg data range from 2/8/22 to 11/15/22. in specific, we calculated a stock percentage change over this period for each company, a volatility index, a 50-day moving average, and a cumulative return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prevents some annoying yfinance outputs from printing - originally, the output took up like 23 pages\n",
    "@contextlib.contextmanager\n",
    "def suppress_output():\n",
    "    with open(os.devnull, 'w') as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        old_stderr = sys.stderr\n",
    "        sys.stdout = devnull\n",
    "        sys.stderr = devnull\n",
    "        try:\n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "            sys.stderr = old_stderr\n",
    "\n",
    "tickers = esg[\"ticker\"].tolist()\n",
    "stock_data = []\n",
    "\n",
    "for ticker in tickers:\n",
    "    try:\n",
    "        # suppresses all of the outputs when grabbing data from yfinance\n",
    "        with suppress_output():  \n",
    "            stock = yf.download(ticker, start = \"2021-01-01\", end = \"2022-12-31\", progress = False)\n",
    "        \n",
    "        if not stock.empty:\n",
    "            # calculating percentage change\n",
    "            percentage_change = ((stock[\"Close\"].iloc[-1] - stock[\"Close\"].iloc[0]) / stock[\"Close\"].iloc[0]) * 100\n",
    "            \n",
    "            # calculating volatility (sd of daily returns)\n",
    "            daily_returns = stock[\"Close\"].pct_change()\n",
    "            volatility = daily_returns.std()\n",
    "            \n",
    "            # calculating 50-day moving average\n",
    "            stock[\"50_day_SMA\"] = stock[\"Close\"].rolling(window=50).mean()\n",
    "            sma_50_day = stock[\"50_day_SMA\"].iloc[-1]\n",
    "            \n",
    "            # calculating cumulative return\n",
    "            cumulative_return = (stock[\"Close\"].iloc[-1] / stock[\"Close\"].iloc[0]) - 1\n",
    "            \n",
    "            stock_data.append({\n",
    "                'ticker': ticker, \n",
    "                'percentage_change': percentage_change,\n",
    "                'volatility': volatility,\n",
    "                '50_day_SMA': sma_50_day,\n",
    "                'cumulative_return': cumulative_return\n",
    "            })\n",
    "            \n",
    "    # also helps to suppress annoying outputs\n",
    "    except (yf.YFTzMissingError, yf.YFPricesMissingError):\n",
    "        pass "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to convert the stock data we extracted from yfinance to a dataframe to merge it with our original esg dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current data shape: (680, 25)\n",
      "\n",
      "  ticker                           name currency  \\\n",
      "0   poww                       Ammo Inc      USD   \n",
      "1   acls       Axcelis Technologies Inc      USD   \n",
      "2   achc  Acadia Healthcare Company Inc      USD   \n",
      "3     cf     CF Industries Holdings Inc      USD   \n",
      "4      t                       AT&T Inc      USD   \n",
      "\n",
      "                        exchange           industry  \\\n",
      "0     NASDAQ NMS - GLOBAL MARKET   Leisure Products   \n",
      "1     NASDAQ NMS - GLOBAL MARKET     Semiconductors   \n",
      "2     NASDAQ NMS - GLOBAL MARKET        Health Care   \n",
      "3  NEW YORK STOCK EXCHANGE, INC.          Chemicals   \n",
      "4  NEW YORK STOCK EXCHANGE, INC.  Telecommunication   \n",
      "\n",
      "                                                logo  \\\n",
      "0  https://static.finnhub.io/logo/8decc6ca0564a89...   \n",
      "1  https://static.finnhub.io/logo/88b5f730-80df-1...   \n",
      "2  https://static.finnhub.io/logo/4b6b2e5a4cfce5b...   \n",
      "3  https://static.finnhub.io/logo/9b57a636-80eb-1...   \n",
      "4  https://static.finnhub.io/logo/7d20269e-80ec-1...   \n",
      "\n",
      "                              weburl environment_grade environment_level  \\\n",
      "0               https://ammoinc.com/                 B            Medium   \n",
      "1           https://www.axcelis.com/                 A              High   \n",
      "2  https://www.acadiahealthcare.com/                BB            Medium   \n",
      "3      https://www.cfindustries.com/                 A              High   \n",
      "4               https://www.att.com/                 B            Medium   \n",
      "\n",
      "  social_grade  ... governance_score total_score last_processing_date  \\\n",
      "0            B  ...              200         657           02-08-2022   \n",
      "1           BB  ...              260        1081           04-16-2022   \n",
      "2            B  ...              220         781           04-16-2022   \n",
      "3           BB  ...              310        1142           04-16-2022   \n",
      "4            B  ...              305         715           04-16-2022   \n",
      "\n",
      "   total_grade  total_level      cik  percentage_change volatility 50_day_SMA  \\\n",
      "0            B       Medium  1015383         -49.709303   0.045699     2.3782   \n",
      "1          BBB         High  1113232         177.482516   0.039289    73.6454   \n",
      "2           BB       Medium  1520697          63.042181   0.021220    82.6706   \n",
      "3          BBB         High  1324404         121.126394   0.027458   101.2440   \n",
      "4            B       Medium   732717         -17.205026   0.015053    18.5720   \n",
      "\n",
      "  cumulative_return  \n",
      "0         -0.497093  \n",
      "1          1.774825  \n",
      "2          0.630422  \n",
      "3          1.211264  \n",
      "4         -0.172050  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "stock_df = pd.DataFrame(stock_data)\n",
    "merged_df = esg.merge(stock_df, on = 'ticker', how = 'left')\n",
    "print(f\"current data shape: {merged_df.shape}\")\n",
    "\n",
    "print(f\"\\n{merged_df.head()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now, we need to drop any rows where the finance data has left null values. this eliminates 60 more of our rows, leaving us with 620 companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-null finance data shape: (620, 25)\n"
     ]
    }
   ],
   "source": [
    "merged_df = merged_df.dropna()\n",
    "print(f\"non-null finance data shape: {merged_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is still a lot of data, but will be helpful for getting industry-level and other general overviews of the data. merged_df will be our main dataset.\n",
    "\n",
    "we also want to create a sample of these 620 companies so that we are able to look at trends and associations at individual company-level as well. to create our sample, we went through the industry list and selected 23 well-known companies from differing industries manually, however, we will probably refine this approach later (this ties into one of our questions for reviewers). sample_companies will be our 2nd dataset then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ticker                                 name currency  \\\n",
      "6      aal          American Airlines Group Inc      USD   \n",
      "10    aapl                            Apple Inc      USD   \n",
      "86     cmg           Chipotle Mexican Grill Inc      USD   \n",
      "121    bro                    Brown & Brown Inc      USD   \n",
      "130    bdx              Becton Dickinson and Co      USD   \n",
      "133    bac                 Bank of America Corp      USD   \n",
      "147    are  Alexandria Real Estate Equities Inc      USD   \n",
      "161   abbv                           Abbvie Inc      USD   \n",
      "189   ebay                             eBay Inc      USD   \n",
      "231     gs              Goldman Sachs Group Inc      USD   \n",
      "235     gm                    General Motors Co      USD   \n",
      "273    duk                     Duke Energy Corp      USD   \n",
      "362   pypl                  PayPal Holdings Inc      USD   \n",
      "428    ual         United Airlines Holdings Inc      USD   \n",
      "429   tmus                      T-Mobile US Inc      USD   \n",
      "430   tsla                            Tesla Inc      USD   \n",
      "450   sbux                       Starbucks Corp      USD   \n",
      "452    crm                       Salesforce Inc      USD   \n",
      "465    dis                       Walt Disney Co      USD   \n",
      "471    tgt                          Target Corp      USD   \n",
      "508    mro                    Marathon Oil Corp      USD   \n",
      "512   meta                   Meta Platforms Inc      USD   \n",
      "660   bbwi                Bath & Body Works Inc      USD   \n",
      "\n",
      "                          exchange                        industry  \\\n",
      "6       NASDAQ NMS - GLOBAL MARKET                        Airlines   \n",
      "10      NASDAQ NMS - GLOBAL MARKET                      Technology   \n",
      "86   NEW YORK STOCK EXCHANGE, INC.  Hotels Restaurants and Leisure   \n",
      "121  NEW YORK STOCK EXCHANGE, INC.                       Insurance   \n",
      "130  NEW YORK STOCK EXCHANGE, INC.                     Health Care   \n",
      "133  NEW YORK STOCK EXCHANGE, INC.                         Banking   \n",
      "147  NEW YORK STOCK EXCHANGE, INC.                     Real Estate   \n",
      "161  NEW YORK STOCK EXCHANGE, INC.                   Biotechnology   \n",
      "189     NASDAQ NMS - GLOBAL MARKET                          Retail   \n",
      "231  NEW YORK STOCK EXCHANGE, INC.              Financial Services   \n",
      "235  NEW YORK STOCK EXCHANGE, INC.                     Automobiles   \n",
      "273  NEW YORK STOCK EXCHANGE, INC.                       Utilities   \n",
      "362     NASDAQ NMS - GLOBAL MARKET                      Technology   \n",
      "428     NASDAQ NMS - GLOBAL MARKET                        Airlines   \n",
      "429     NASDAQ NMS - GLOBAL MARKET               Telecommunication   \n",
      "430     NASDAQ NMS - GLOBAL MARKET                     Automobiles   \n",
      "450     NASDAQ NMS - GLOBAL MARKET  Hotels Restaurants and Leisure   \n",
      "452  NEW YORK STOCK EXCHANGE, INC.                      Technology   \n",
      "465  NEW YORK STOCK EXCHANGE, INC.                           Media   \n",
      "471  NEW YORK STOCK EXCHANGE, INC.                          Retail   \n",
      "508  NEW YORK STOCK EXCHANGE, INC.                          Energy   \n",
      "512     NASDAQ NMS - GLOBAL MARKET                           Media   \n",
      "660  NEW YORK STOCK EXCHANGE, INC.                          Retail   \n",
      "\n",
      "                                                  logo  \\\n",
      "6    https://static2.finnhub.io/file/publicdatany/f...   \n",
      "10   https://static.finnhub.io/logo/87cb30d8-80df-1...   \n",
      "86   https://static.finnhub.io/logo/a551a6c2-80eb-1...   \n",
      "121  https://static.finnhub.io/logo/8d4bb0d8-80eb-1...   \n",
      "130  https://static.finnhub.io/logo/82e1f20c-80eb-1...   \n",
      "133  https://static2.finnhub.io/file/publicdatany/f...   \n",
      "147  https://static.finnhub.io/logo/ffde2ccf9a1b68d...   \n",
      "161  https://static.finnhub.io/logo/8806d72c-80cd-1...   \n",
      "189  https://static.finnhub.io/logo/919a6270-826a-1...   \n",
      "231  https://static.finnhub.io/logo/7ba3bd9e8fc91f9...   \n",
      "235  https://static.finnhub.io/logo/9253db78-80c9-1...   \n",
      "273  https://static.finnhub.io/logo/c6386312-80eb-1...   \n",
      "362  https://static.finnhub.io/logo/58e310c0-80d2-1...   \n",
      "428  https://static.finnhub.io/logo/b3f34b67dcba172...   \n",
      "429  https://static.finnhub.io/logo/4ffaa8b8-80ec-1...   \n",
      "430  https://static.finnhub.io/logo/2dd96524-80c9-1...   \n",
      "450  https://static.finnhub.io/logo/8d4c97ac-80e0-1...   \n",
      "452  https://static.finnhub.io/logo/5a800a68f67c85e...   \n",
      "465  https://static.finnhub.io/logo/ef50b4a2b263c84...   \n",
      "471  https://static.finnhub.io/logo/83bbf858-80ec-1...   \n",
      "508  https://static.finnhub.io/logo/2f57969a-80ec-1...   \n",
      "512  https://static2.finnhub.io/file/publicdatany/f...   \n",
      "660  https://static.finnhub.io/logo/1b846d4a-80ec-1...   \n",
      "\n",
      "                                    weburl environment_grade  \\\n",
      "6    https://americanairlines.gcs-web.com/                 B   \n",
      "10                  https://www.apple.com/                BB   \n",
      "86               https://www.chipotle.com/                 B   \n",
      "121           https://www.bbinsurance.com/               BBB   \n",
      "130                    https://www.bd.com/                AA   \n",
      "133          https://www.bankofamerica.com                 B   \n",
      "147                   https://www.are.com/                AA   \n",
      "161                https://www.abbvie.com/                 A   \n",
      "189               https://www.ebayinc.com/                 A   \n",
      "231          https://www.goldmansachs.com/                 A   \n",
      "235                    https://www.gm.com/                 A   \n",
      "273           https://www.duke-energy.com/                AA   \n",
      "362                https://www.paypal.com/                BB   \n",
      "428                 https://ir.united.com/                 B   \n",
      "429              https://www.t-mobile.com/                BB   \n",
      "430                 https://www.tesla.com/                 A   \n",
      "450             https://www.starbucks.com/               BBB   \n",
      "452            https://www.salesforce.com/                 B   \n",
      "465      https://thewaltdisneycompany.com/                 A   \n",
      "471          https://corporate.target.com/                 A   \n",
      "508           https://www.marathonoil.com/                 A   \n",
      "512               https://www.facebook.com                 B   \n",
      "660                https://www.bbwinc.com/                 A   \n",
      "\n",
      "    environment_level social_grade  ... governance_score total_score  \\\n",
      "6              Medium            B  ...              265         746   \n",
      "10             Medium            B  ...              255         891   \n",
      "86             Medium            B  ...              213         664   \n",
      "121              High           BB  ...              300        1025   \n",
      "130         Excellent           BB  ...              315        1306   \n",
      "133            Medium           BB  ...              265         879   \n",
      "147         Excellent           BB  ...              345        1282   \n",
      "161              High           BB  ...              300        1122   \n",
      "189              High           BB  ...              305        1107   \n",
      "231              High           BB  ...              305        1135   \n",
      "235              High           BB  ...              255        1068   \n",
      "273         Excellent           BB  ...              328        1294   \n",
      "362            Medium            B  ...              285         899   \n",
      "428            Medium            B  ...              221         629   \n",
      "429            Medium           BB  ...              230         903   \n",
      "430              High          CCC  ...              278         993   \n",
      "450              High           BB  ...              295        1155   \n",
      "452            Medium            B  ...              200         656   \n",
      "465              High           BB  ...              321        1147   \n",
      "471              High           BB  ...              313        1205   \n",
      "508              High           BB  ...              305        1148   \n",
      "512            Medium            B  ...              215         652   \n",
      "660              High           BB  ...              300        1128   \n",
      "\n",
      "    last_processing_date  total_grade  total_level      cik  \\\n",
      "6             04-16-2022            B       Medium     6201   \n",
      "10            04-16-2022           BB       Medium   320193   \n",
      "86            04-16-2022            B       Medium  1058090   \n",
      "121           04-16-2022          BBB         High    79282   \n",
      "130           04-16-2022            A         High    10795   \n",
      "133           04-16-2022           BB       Medium    70858   \n",
      "147           04-16-2022            A         High  1035443   \n",
      "161           04-16-2022          BBB         High  1551152   \n",
      "189           04-17-2022          BBB         High  1065088   \n",
      "231           04-17-2022          BBB         High   886982   \n",
      "235           04-17-2022          BBB         High  1467858   \n",
      "273           04-17-2022            A         High  1326160   \n",
      "362           04-18-2022           BB       Medium  1633917   \n",
      "428           04-19-2022            B       Medium   100517   \n",
      "429           04-19-2022          BBB         High  1283699   \n",
      "430           04-19-2022          BBB         High  1318605   \n",
      "450           04-19-2022          BBB         High   829224   \n",
      "452           04-19-2022            B       Medium  1108524   \n",
      "465           04-19-2022          BBB         High  1744489   \n",
      "471           04-19-2022            A         High    27419   \n",
      "508           04-21-2022          BBB         High   101778   \n",
      "512           04-22-2022            B       Medium  1326801   \n",
      "660           11-06-2022          BBB         High   701985   \n",
      "\n",
      "     percentage_change volatility  50_day_SMA cumulative_return  \n",
      "6           -15.928618   0.032685   13.750600         -0.159286  \n",
      "10            0.401815   0.019434  143.075999          0.004018  \n",
      "86            5.182998   0.021798   29.759500          0.051830  \n",
      "121          22.912628   0.017001   57.558000          0.229126  \n",
      "130           3.971877   0.013555  238.320800          0.039719  \n",
      "133          10.289704   0.018449   35.125800          0.102897  \n",
      "147         -14.698135   0.015891  146.813401         -0.146981  \n",
      "161          53.315620   0.013467  156.389600          0.533156  \n",
      "189         -19.475726   0.022458   42.343200         -0.194757  \n",
      "231          29.577360   0.017342  359.515798          0.295774  \n",
      "235         -16.958774   0.026137   37.856800         -0.169588  \n",
      "273          14.803254   0.012113   97.451199          0.148033  \n",
      "362         -69.291134   0.030809   78.270200         -0.692911  \n",
      "428          -9.440308   0.031424   41.972600         -0.094403  \n",
      "429           5.716233   0.016882  145.478800          0.057162  \n",
      "430         -49.362128   0.038491  179.794800         -0.493621  \n",
      "450          -3.782737   0.018825   96.071000         -0.037827  \n",
      "452         -39.816623   0.024519  145.095600         -0.398166  \n",
      "465         -51.103106   0.019865   95.233000         -0.511031  \n",
      "471         -16.095260   0.023088  157.749400         -0.160953  \n",
      "508         296.339678   0.033952   29.454800          2.963397  \n",
      "512         -55.253962   0.031551  113.209200         -0.552540  \n",
      "660          31.634286   0.033038   38.121400          0.316343  \n",
      "\n",
      "[23 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "companies = [\"Walt Disney Co\", \"American Airlines Group Inc\", \"Apple Inc\", \"eBay Inc\", \"Goldman Sachs Group Inc\", \n",
    "             \"Meta Platforms Inc\", \"Starbucks Corp\", \"PayPal Holdings Inc\", \"United Airlines Holdings Inc\", \n",
    "             \"Bath & Body Works Inc\", \"Abbvie Inc\", \"Alexandria Real Estate Equities Inc\", \n",
    "             \"Becton Dickinson and Co\", \"Brown & Brown Inc\", \"Duke Energy Corp\", \"T-Mobile US Inc\",\n",
    "             \"Marathon Oil Corp\", \"Chipotle Mexican Grill Inc\", \"Target Corp\", \n",
    "             \"General Motors Co\", \"Salesforce Inc\", \"Tesla Inc\", \"Bank of America Corp\"]\n",
    "\n",
    "sample_companies = merged_df[merged_df[\"name\"].isin(companies)]\n",
    "print(sample_companies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "finally, we also extracted some general S&P 500 data from yfinance, ranging from the dates of 1/1/21 and 12/31/22 for the same reason. we are pulling this data so that we can compare stock performance of the individual companies to the overall S&P 500 in the same time range. sp500 will be our 3rd dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Start Price    End Price  Rate of Change\n",
      "Date                                                \n",
      "2021-01-04  3764.610107  3700.649902       -1.698986\n",
      "2021-01-05  3698.020020  3726.860107        0.779879\n",
      "2021-01-06  3712.199951  3748.139893        0.968157\n",
      "2021-01-07  3764.709961  3803.790039        1.038063\n",
      "2021-01-08  3815.050049  3824.679932        0.252418\n",
      "...                 ...          ...             ...\n",
      "2022-12-23  3815.110107  3844.820068        0.778745\n",
      "2022-12-27  3843.340088  3829.250000       -0.366610\n",
      "2022-12-28  3829.560059  3783.219971       -1.210063\n",
      "2022-12-29  3805.449951  3849.280029        1.151771\n",
      "2022-12-30  3829.060059  3839.500000        0.272650\n",
      "\n",
      "[503 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "sp500data = yf.download('^GSPC', start = '2021-01-01', end = '2022-12-31', progress = False)\n",
    "sp500 = pd.DataFrame({\n",
    "    'Date': sp500data.index,\n",
    "    'Start Price': sp500data['Open'],\n",
    "    'End Price': sp500data['Close'],\n",
    "    'Rate of Change': ((sp500data['Close'] - sp500data['Open']) / sp500data['Open']) * 100 })\n",
    "\n",
    "sp500.set_index('Date', inplace = True)\n",
    "print(sp500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### __Exploratory Data Analysis__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part one - exploring different average environmental, social, governance, and total ESG scores by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_esg_by_industry = merged_df.groupby('industry')['total_score'].mean().reset_index()\n",
    "avg_esg_by_industry.columns = ['Industry', 'Average Total ESG Score']\n",
    "\n",
    "avg_esg_by_industry = avg_esg_by_industry.sort_values(by = 'Average Total ESG Score', ascending = False)\n",
    "print(\"best average ESG scores\")\n",
    "print(avg_esg_by_industry.head(6))\n",
    "print(\"\")\n",
    "\n",
    "avg_esg_by_industry = avg_esg_by_industry.sort_values(by = 'Average Total ESG Score', ascending = True)\n",
    "print(\"worst average ESG scores\")\n",
    "print(avg_esg_by_industry.head(6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (14, 10))\n",
    "sns.barplot(x = 'Average Total ESG Score', y = 'Industry', data = avg_esg_by_industry, color = \"#b97df3\")\n",
    "plt.title('Average Total ESG Score by Industry', horizontalalignment = 'center', fontsize = 16, fontweight = 'bold', )\n",
    "plt.xlabel('Average Total ESG Score', fontsize = 14, fontweight = 'bold')\n",
    "plt.ylabel('Industry Name', fontsize = 14, fontweight = 'bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interestingly (and somewhat predictably) - the industries with the lowest ESG scores are Metals & Mining, Aerospace & Defense, Diversified Consumer Services, Hotels, Restaurants & Leisure, Leisure Products, Auto Components, Airlines, and Automobiles. the industries with the highest ESG scores are Utilities, Tobacco, Industrial Conglomerates, Packaging, and Energy. \n",
    "\n",
    "future steps: sort different industries by just Environmental score, just Social score, and just Governance score to see if these differ significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns for correlation\n",
    "score_columns = ['environment_score', 'social_score', 'governance_score', 'total_score']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr_matrix = merged_df[score_columns].corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Create a heatmap to visualize the correlation matrix\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', square=True, cbar_kws={\"shrink\": .8}, linewidths=0.5)\n",
    "\n",
    "# Set titles and labels\n",
    "plt.title('Correlation Matrix of ESG Scores', fontsize=16)\n",
    "plt.xticks(rotation=45)\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use yfinance to pull stock information of selected stocks.\n",
    "esg.loc[:, 'ticker'] = esg['ticker'].astype(str)\n",
    "esg.loc[:, 'name'] = esg['name'].astype(str)\n",
    "tickers = esg['ticker'].tolist()\n",
    "\n",
    "#Add Start Price, End Price, and Rate of Change (%) of each company to the dataset esg\n",
    "esg.loc[:, 'Start Price'] = None\n",
    "esg.loc[:, 'End Price'] = None\n",
    "esg.loc[:, 'Rate of Change (%)'] = None\n",
    "\n",
    "# Loop through each row of the DataFrame to get stock information for each company\n",
    "for index, row in esg.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    \n",
    "    # Download stock data for 2023\n",
    "    data = yf.download(ticker, start='2021-04-01',end='2022-04-01')\n",
    "    \n",
    "    # Ensure data exists for the given period\n",
    "    if not data.empty:\n",
    "        start_price = data['Adj Close'].iloc[0]\n",
    "        end_price = data['Adj Close'].iloc[-1]\n",
    "        rate_of_change = ((end_price - start_price) / start_price) * 100\n",
    "        \n",
    "        # Add the stock data to the relevant columns in the DataFrame using .loc[]\n",
    "        esg.loc[index, 'Start Price'] = start_price\n",
    "        esg.loc[index, 'End Price'] = end_price\n",
    "        esg.loc[index, 'Rate of Change (%)'] = rate_of_change\n",
    "\n",
    "print(esg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning to only have certain companies that represent a variety of industries\n",
    "\n",
    "companies = [\"Walt Disney Co\", \"American Airlines Group Inc\", \"Apple Inc\", \"eBay Inc\", \"Goldman Sachs Group Inc\", \n",
    "             \"Meta Platforms Inc\", \"Starbucks Corp\", \"PayPal Holdings Inc\", \"United Airlines Holdings Inc\", \n",
    "             \"Bath & Body Works Inc\", \"Abbvie Inc\", \"Alexandria Real Estate Equities Inc\", \n",
    "             \"Becton Dickinson and Co\", \"Brown & Brown Inc\", \"Duke Energy Corp\", \"T-Mobile US Inc\",\n",
    "             \"Marathon Oil Corp\", \"Chipotle Mexican Grill Inc\", \"Target Corp\", \n",
    "             \"General Motors Co\", \"Salesforce Inc\", \"Tesla Inc\", \"Bank of America Corp\"]\n",
    "\n",
    "relevant_esg = esg[esg[\"name\"].isin(companies)]\n",
    "print(relevant_esg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use yfinance to pull stock information of selected stocks.\n",
    "relevant_esg.loc[:, 'ticker'] = relevant_esg['ticker'].astype(str)\n",
    "relevant_esg.loc[:, 'name'] = relevant_esg['name'].astype(str)\n",
    "tickers = relevant_esg['ticker'].tolist()\n",
    "#Add Start Price, End Price, and Rate of Change (%) of each company to the dataset relevent.esg\n",
    "relevant_esg.loc[:, 'Start Price'] = None\n",
    "relevant_esg.loc[:, 'End Price'] = None\n",
    "relevant_esg.loc[:, 'Rate of Change (%)'] = None\n",
    "\n",
    "# Loop through each row of the DataFrame to get stock information for each company\n",
    "for index, row in relevant_esg.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    \n",
    "    # Download stock data for 2023\n",
    "    data = yf.download(ticker, start='2021-04-01',end='2022-04-01')\n",
    "    \n",
    "    # Ensure data exists for the given period\n",
    "    if not data.empty:\n",
    "        start_price = data['Adj Close'].iloc[0]\n",
    "        end_price = data['Adj Close'].iloc[-1]\n",
    "        rate_of_change = ((end_price - start_price) / start_price) * 100\n",
    "        \n",
    "        # Add the stock data to the relevant columns in the DataFrame using .loc[]\n",
    "        relevant_esg.loc[index, 'Start Price'] = start_price\n",
    "        relevant_esg.loc[index, 'End Price'] = end_price\n",
    "        relevant_esg.loc[index, 'Rate of Change (%)'] = rate_of_change\n",
    "\n",
    "print(relevant_esg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Start Price, End Price, and Rate of Change (%) of each company to the dataset esg\n",
    "esg.loc[:, 'ticker'] = esg['ticker'].astype(str)\n",
    "esg.loc[:, 'name'] = esg['name'].astype(str)\n",
    "tickers = esg['ticker'].tolist()\n",
    "\n",
    "# Add columns for Start Price, End Price, and Rate of Change (%)\n",
    "esg['Start Price'] = None\n",
    "esg['End Price'] = None\n",
    "esg['Rate of Change (%)'] = None\n",
    "\n",
    "# Loop through each row of the DataFrame to get stock information for each company\n",
    "for index, row in esg.iterrows():\n",
    "    ticker = row['ticker']\n",
    "    \n",
    "    # Skip rows where the ticker is not valid\n",
    "    if ticker == 'nan' or ticker.strip() == \"\":\n",
    "        continue\n",
    "    \n",
    "    # Download stock data for the given ticker\n",
    "    data = yf.download(ticker, start='2021-04-01', end='2022-04-01')\n",
    "    \n",
    "    # Ensure data exists for the given period\n",
    "    if not data.empty:\n",
    "        start_price = data['Adj Close'].iloc[0]\n",
    "        end_price = data['Adj Close'].iloc[-1]\n",
    "        rate_of_change = ((end_price - start_price) / start_price) * 100\n",
    "        \n",
    "        # Add the stock data to the relevant columns in the DataFrame\n",
    "        esg.loc[index, 'Start Price'] = start_price\n",
    "        esg.loc[index, 'End Price'] = end_price\n",
    "        esg.loc[index, 'Rate of Change (%)'] = rate_of_change\n",
    "\n",
    "#Remove companies with missing value on stock information:\n",
    "esg.dropna(subset=['Start Price', 'End Price', 'Rate of Change (%)'], inplace=True)\n",
    "\n",
    "#show the first 15 rows of cleaned esg\n",
    "print(esg.iloc[0:15,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Violin Plot: Governance Score by Environment Level\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=esg, x='environment_level', y='governance_score', palette='muted')\n",
    "plt.title('Governance Scores by Environment Level', fontsize=16)\n",
    "plt.xlabel('Environment Level')\n",
    "plt.ylabel('Governance Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of total_score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(esg['total_score'], kde=True, bins=20)\n",
    "plt.title('Distribution of Total ESG Scores', fontsize=16)\n",
    "plt.xlabel('Total Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot of Total Scores by Total Grade\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=esg, x='total_grade', y='total_score', palette='Set2')\n",
    "plt.title('Total ESG Scores by Grade', fontsize=16)\n",
    "plt.xlabel('Total Grade')\n",
    "plt.ylabel('Total Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatter Plot: Rate of Change vs. Total ESG Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=esg, x='total_score', y='Rate of Change (%)', hue='total_grade', palette='coolwarm', s=100)\n",
    "plt.title('Rate of Change (%) vs. Total ESG Score', fontsize=16)\n",
    "plt.xlabel('Total ESG Score')\n",
    "plt.ylabel('Rate of Change (%)')\n",
    "plt.legend(title=\"ESG Grade\", loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Boxplot: Rate of Change by Environment Grade\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=esg, x='environment_grade', y='Rate of Change (%)', palette='Set2')\n",
    "plt.title('Rate of Change (%) by Environmental Grade', fontsize=16)\n",
    "plt.xlabel('Environment Grade')\n",
    "plt.ylabel('Rate of Change (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Violin Plot: Rate of Change by Social Grade\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(data=esg, x='social_grade', y='Rate of Change (%)', palette='muted')\n",
    "plt.title('Rate of Change (%) by Social Grade', fontsize=16)\n",
    "plt.xlabel('Social Grade')\n",
    "plt.ylabel('Rate of Change (%)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix=esg[['environment_score', 'social_score', 'governance_score', 'Rate of Change (%)']].corr()\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix Between ESG Subscores and Stock Price Change')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "correlation_environment = esg['environment_score'].corr(esg['Rate of Change (%)'])\n",
    "correlation_social = esg['social_score'].corr(esg['Rate of Change (%)'])\n",
    "correlation_governance = esg['governance_score'].corr(esg['Rate of Change (%)'])\n",
    "\n",
    "print(f'Correlation between Environmental Score and Rate of Change (%): {correlation_environment:.3f}')\n",
    "print(f'Correlation between Social Score and Rate of Change (%): {correlation_social:.3f}')\n",
    "print(f'Correlation between Governance Score and Rate of Change (%): {correlation_governance:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for each ESG subscore\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(esg['environment_score'].dropna(), bins=20, color='skyblue', edgecolor='black')\n",
    "plt.xlabel('Environmental Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Environmental Scores')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(esg['social_score'].dropna(), bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.xlabel('Social Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Social Scores')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(esg['governance_score'].dropna(), bins=20, color='lightcoral', edgecolor='black')\n",
    "plt.xlabel('Governance Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Governance Scores')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_scores = relevant_esg['environment_score'].values\n",
    "soc_scores = relevant_esg['social_score'].values\n",
    "gov_scores = relevant_esg['governance_score'].values\n",
    "filtered_companies = relevant_esg['name'].values\n",
    "\n",
    "x = np.arange(len(filtered_companies))\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(x, env_scores, color='skyblue', label='Environmental Score')\n",
    "plt.bar(x, soc_scores, bottom=env_scores, color='lightgreen', label='Social Score')\n",
    "plt.bar(x, gov_scores, bottom=env_scores + soc_scores, color='lightcoral', label='Governance Score')\n",
    "\n",
    "plt.xticks(x, filtered_companies, rotation=45, ha='right')\n",
    "plt.xlabel('Company')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Stacked Bar Chart of ESG Scores by Company')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(list(relevant_esg['ticker']), start='2023-01-01', end='2024-01-01')['Adj Close']\n",
    "        \n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "for ticker in data.columns:\n",
    "    plt.plot(data.index, data[ticker], label=ticker)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Adjusted Closing Price (USD)')\n",
    "plt.title('Stock Price Changes Over Time for Selected Companies')\n",
    "plt.legend(loc='upper left', fontsize='small')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = relevant_esg[['environment_score', 'social_score','governance_score']]   # Independent variables\n",
    "y = relevant_esg['Rate of Change (%)']   # Dependent variable\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "print(f\"Environmental Score Coefficient: {model.coef_[0]}\")\n",
    "print(f\"Social Score Coefficient: {model.coef_[1]}\")\n",
    "print(f\"Governance Score Coefficient: {model.coef_[2]}\")\n",
    "print(f\"Intercept: {model.intercept_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Coefficients Interpretation\n",
    "\n",
    "For every 1-unit increase in the Environmental score (assuming all other factors remain constant), the stock return is expected to increase by 0.1079 units. The positive coefficient suggests that higher Environmental scores are associated with better stock performance (or higher returns).\n",
    "\n",
    "For every 1-unit increase in the Social score (with other variables constant), the stock return is expected to decrease by 0.0237 units. The negative coefficient indicates that better Social scores might be associated with lower stock performance, but generally, since the coefficient is so close to 0, Social scores seem to have little impact on stock performance.\n",
    "\n",
    "For every 1-unit increase in the Governance score (with other variables constant), stock return is expected to decrease by 0.0750 units. This negative coefficient suggests that improvements in governance (e.g., stricter regulation or more ethical practices) are associated with slightly lower stock returns. This could imply that governance improvements come at a financial cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esg_corr = relevant_esg.loc[:, ['environment_score', 'social_score',\n",
    "                                'governance_score']] \n",
    "print(esg_corr.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(esg_corr.cov(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation and Covariance \n",
    "\n",
    "Let's observe the correlation/covariance between the different ESG scores themselves! All the correlations are positive, meaning that there is positive correlation between the scores (when one increases, the other does too). Governance and Environment have a particularly strong correlation, suggesting that companies who invest in environmental factors likely also care about governance (or perhaps some government regulations align with environmental issues). On the other hand, social factors seem to have just a moderately positive relationship with both the other variables.\n",
    "\n",
    "While the covariance values agree with these claims, it's interesting to note how large the variance is for Environmental Scores (20758.63). This suggests that there is a large spread in environmental performance among the companies we chose, while governance scores are much more consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Description\n",
    "\n",
    "This dataset contains ESG (Environmental, Social, and Governance) scores for 722 publicly traded companies, and represents a variety of different industries. Each row represents an individual company. The 21 columns include a CIK identifier, last processing date of the ESG data, company information (currency, logo/website URLs), environmental scores and ratings, social scores and ratings, governance scores and ratings, and overall ESG scores and ratings. We can combine this dataset with the Yahoo! Finance library in Python (yfinance, maintained by Ran Aroussi) to investigate if a company’s ESG score impacts its stock performance over time (time-series analysis): pypi.org/project/yfinance/. We do not intend to scrape data ourselves, but plan to utilize the yfinance library, which downloads market data from the Yahoo! Finance API, and appears to be free to use. We also will most likely filter this dataset from all 722 companies to just a few major companies of interest from select industries. Overall, our research question may be along the lines of “How do ESG ratings influence stock performance?” or “Do companies with high environmental ratings show less stock price volatility?”\n",
    "\n",
    "\n",
    "We are using data from a Kaggle csv, and joining this to the yfinance library. First, we downloaded the ESG Kaggle csv, where each row corresponds to a different publicly traded company; this also contains ESG metrics for each company. We have filtered this dataset to only include companies that are traded in USD, and the columns all refer to a specific aspect of the company, such as industry, name, stock close/open/high/low prices, and ESG rating indexes. Then, we join this data to the yfinance library (Yahoo Finance) - from yfinance, we take the stock closing price of the company on 4/1/21 and 4/1/22. We also created a % Change variable, which measures the percentage change in the company stock closing price over the 2 years. All of this information is included in our large dataset - so the columns are company stock ticker, company name, currency, exchange, industry, logo, web url, environment grade, environment level, social grade, governance grade, governance level, environmental score, social score, governance score, total score, last processing date, total grade, total level, central index key, stock closing price in 4/1/21, stock closing price in 4/1/22, and the percent change between these. Our smaller dataset is meant to be a 'sample' of the original dataset with 722 rows, and involves a few companies that we hand-picked by notability. It contains all of the same columns, but only contains 23 companies. \n",
    "\n",
    "Our dataframes were created to show different stock prices of various companies over different date ranges, and the original ESG company data was created to compile ESG information for 700 mid / large-cap companies across various industries. Our combined dataframes was made to contrast both stock prices and ESG ratings of companies, and explore any associations. The original ESG company dataset was 'funded' by the efforts of Kaggle user Alistair King, and the yfinance dataset was created by Ran Aroussi as a way around the recent-ish Yahoo Finance API deprecation. For the ESG rating dataset, only mid/large-cap companies are included, so this influences the specific companies that are present in the dataset (the data that was observed and recorded) -- smaller companies will not be 'observed' here. \n",
    "\n",
    "The preprocessing was described above; we filtered our 722 row dataset for NaNs for our large dataset, and then for our sample dataset, we filtered all 722 companies down to 23 of interest, and joined all data to the yfinance library. Specifically, for each company, we acquired the stock closing price for 4/1/21 and 4/1/24, then created a stock change percentage variable between these two dates. \n",
    "\n",
    "Individuals are not involved in the data directly, as each observation corresponds to an entire company.\n",
    "\n",
    "Our raw source data can be found in the yfinance library and https://www.kaggle.com/datasets/alistairking/public-company-esg-ratings-dataset/data, and the specific csv is here: https://github.com/phoebewang28/info-2950-project/blob/main/esg_data.csv. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Data Limitations\n",
    "    \n",
    "1. For our smaller dataset, the current sample of 23 companies was chosen manually by us as we wanted to get a range of industries that are well-known. This is limited to the companies that only use USD, and again, this data only records large/mid-cap companies, so this selection may not be fully representative of all US companies with ESG ratings. Depending on the results of of our analyses, we may consider random sampling or expanding the sample size to improve representativeness of our sample dataset.\n",
    "\n",
    "2. We are currently comparing the rate of change of the sample stocks to the S&P 500, but other measures of stock performance might provide more valuable insights. For now, we are focusing on the rate of change between the closing prices of 4/1/21 and 4/1/22. \n",
    "\n",
    "3. Some stock data from yfinance is missing date information, which causes missing values when extracting prices. One company in our sample had this issue, so we had to exclude it to ensure consistency.\n",
    "\n",
    "4. Since we are exploring potential connections between ESG ratings and company stock performance, we may need to sample not only by industry but also by ESG rating levels to ensure a more balanced and comprehensive analysis of the different ESG performance tiers (for our sample dataset)\n",
    "\n",
    "5. ESG is a constent value retrieved from different days for each company in the month of April, 2022, while stock prices for these companies changes over time. We're unable to perform time-series analysis on ESG rating and stock informations due to the fact. \n",
    "\n",
    "6. ESG is evaluated annually, which might not be accuratly tracking the actual environmental performance of the company. Thus, when considering short-term impact of the company's esg policies, it's likely for that policy change to affect stock but not reflected on company's ESG rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Questions for Reviewers\n",
    "\n",
    "1. After combining our yfinance and ESG data, do we have large enough datasets to satisfy the complexity requirement for the research question?\n",
    "   \n",
    "2. Any advice recommanded to follow when we trying to take sample from the population? maybe by industry? how many industry to take sample from? maybe stratify to include all ESG grade? (as a reminder - we have one big dataset with 700+ companies and joined data that we did some EDA with, but we also want to include a smaller sample dataset so we can look at some individual companies as well).\n",
    "   \n",
    "3. How many visualization and statistics are recommanded for the final project? (ballpark range would be helpful) Do the visualizations we currently have seem like they're on the right path for the final phases?\n",
    "   \n",
    "4. Regarding the visualizations and chunks we have made for our EDA so far: should we explore these specific visualizations more in depth? OR should we expand our DA to other variables in the datasets that we maybe haven't used yet?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info2950",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
